{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Четвертая неделя\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выполнил Ким Антон \n",
    "#### В рамках курса \"Введение в машинное обучение\" от Высшей школы экономики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Линейная регрессия: прогноз оклада по описанию вакансии"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Введение\n",
    "Линейные методы хорошо подходят для работы с разреженными данными — к таковым относятся, например, тексты. Это можно объяснить высокой скоростью обучения и небольшим количеством параметров, благодаря чему удается избежать переобучения.\n",
    "\n",
    "Линейная регрессия имеет несколько разновидностей в зависимости от того, какой регуляризатор используется. Мы будем работать с гребневой регрессией, где применяется квадратичный, или L2-регуляризатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План работы\n",
    "<ul>\n",
    " <li>использовать линейную регрессию</li>\n",
    " <li>применять линейную регрессию к текстовым данным</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/week_4_salary-train.csv')\n",
    "data_test = pd.read_csv('data/week_4_salary-test-mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>International Sales Manager London ****k  ****...</td>\n",
       "      <td>London</td>\n",
       "      <td>permanent</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An ideal opportunity for an individual that ha...</td>\n",
       "      <td>London</td>\n",
       "      <td>permanent</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Online Content and Brand Manager// Luxury Reta...</td>\n",
       "      <td>South East London</td>\n",
       "      <td>permanent</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A great local marketleader is seeking a perman...</td>\n",
       "      <td>Dereham</td>\n",
       "      <td>permanent</td>\n",
       "      <td>22500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Registered Nurse / RGN  Nursing Home for Young...</td>\n",
       "      <td>Sutton Coldfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     FullDescription LocationNormalized  \\\n",
       "0  International Sales Manager London ****k  ****...             London   \n",
       "1  An ideal opportunity for an individual that ha...             London   \n",
       "2  Online Content and Brand Manager// Luxury Reta...  South East London   \n",
       "3  A great local marketleader is seeking a perman...            Dereham   \n",
       "4  Registered Nurse / RGN  Nursing Home for Young...   Sutton Coldfield   \n",
       "\n",
       "  ContractTime  SalaryNormalized  \n",
       "0    permanent             33000  \n",
       "1    permanent             50000  \n",
       "2    permanent             40000  \n",
       "3    permanent             22500  \n",
       "4          NaN             20355  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   FullDescription     60000 non-null  object\n",
      " 1   LocationNormalized  60000 non-null  object\n",
      " 2   ContractTime        44418 non-null  object\n",
      " 3   SalaryNormalized    60000 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инструкции по выполнению\n",
    "Для извлечения **TF-IDF**-признаков из текстов воспользуйтесь классом `sklearn.feature_extraction.text.TfidfVectorizer`.\n",
    "\n",
    "Для предсказания целевой переменной мы будем использовать гребневую регрессию, которая реализована в классе `sklearn.linear_model.Ridge`.\n",
    "\n",
    "Обратите внимание, что признаки **LocationNormalized** и **ContractTime** являются строковыми, и поэтому с ними нельзя работать напрямую. Такие нечисловые признаки с неупорядоченными значениями называют категориальными или номинальными. Типичный подход к их обработке — кодирование категориального признака с m возможными значениями с помощью m бинарных признаков. Каждый бинарный признак соответствует одному из возможных значений категориального признака и является индикатором того, что на данном объекте он принимает данное значение. Данный подход иногда называют **one-hot-кодированием**. Воспользуйтесь им, чтобы перекодировать признаки **LocationNormalized** и **ContractTime**. Он уже реализован в классе `sklearn.feature_extraction.DictVectorizer`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Загрузите данные об описаниях вакансий и соответствующих годовых зарплатах из файла salary-train.csv. Проведите предобработку:\n",
    "<ul>\n",
    "    <li>Приведите тексты к нижнему регистру.</li>\n",
    "    <li>Замените все, кроме букв и цифр, на пробелы — это облегчит дальнейшее разделение текста на слова.</li>\n",
    "    <li>Примените TfidfVectorizer для преобразования текстов в векторы признаков. Оставьте только те слова, которые встречаются хотя бы в 5 объектах</li>    \n",
    "    <li>Замените пропуски в столбцах LocationNormalized и ContractTime на специальную строку 'nan'.</li>\n",
    "    <li>Примените DictVectorizer для получения one-hot-кодирования признаков LocationNormalized и ContractTime.</li>\n",
    "    <li>Объедините все полученные признаки в одну матрицу \"объекты-признаки\". Обратите внимание, что матрицы для текстов и категориальных признаков являются разреженными.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['ContractTime'].fillna('nan', inplace=True)\n",
    "data_train['FullDescription'] = data_train['FullDescription'].apply(lambda s: re.sub('[^a-z0-9]', \n",
    "                                                                                 ' ', s.lower()))\n",
    "tfid = TfidfVectorizer(min_df=5)\n",
    "X_train = tfid.fit_transform(data_train['FullDescription'])\n",
    "X_test = tfid.transform(data_test['FullDescription'])\n",
    "\n",
    "enc = DictVectorizer()\n",
    "X_train_cat = enc.fit_transform(data_train[['ContractTime', 'LocationNormalized']].to_dict('records'))\n",
    "X_test_cat = enc.transform(data_test[['ContractTime', 'LocationNormalized']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = hstack([X_train, \n",
    "               X_train_cat])\n",
    "test = hstack([X_test, \n",
    "               X_test_cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Обучите гребневую регрессию \n",
    "с параметрами alpha=1 и random_state=241. Целевая переменная записана в столбце SalaryNormalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge()\n",
    "\n",
    "model.fit(train, data_train['SalaryNormalized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Постройте прогнозы для двух примеров из файла salary-test-mini.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56582.8905928 , 37133.96512551])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Составление фондового индекса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Введение\n",
    "Метод главных компонент (principal component analysis, PCA) — это один из методов обучения без учителя, который позволяет сформировать новые признаки, являющиеся линейными комбинациями старых. При этом новые признаки строятся так, чтобы сохранить как можно больше дисперсии в данных. Иными словами, метод главных компонент понижает размерность данных оптимальным с точки зрения сохранения дисперсии способом.\n",
    "\n",
    "Основным параметром метода главных компонент является количество новых признаков. Как и в большинстве методов машинного обучения, нет четких рекомендаций по поводу выбора значения этого параметров. Один из подходов — выбирать минимальное число компонент, при котором объясняется не менее определенной доли дисперсии (это означает, что в выборке сохраняется данная доля от исходной дисперсии).\n",
    "\n",
    "В этом задании понадобится измерять схожесть двух наборов величин. Если имеется набор пар измерений (например, одна пара — предсказания двух классификаторов для одного и того же объекта), то охарактеризовать их зависимость друг от друга можно с помощью корреляции Пирсона. Она принимает значения от -1 до 1 и показывает, насколько данные величины линейно зависимы. Если корреляция равна -1 или 1, то величины линейно выражаются друг через друга. Если она равна нулю, то линейная зависимость между величинами отсутствует."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План работы\n",
    "<ul>\n",
    "    <li>работать с методом главных компонент</li>\n",
    "    <li>использовать его для вычисления улучшенного индекса Доу-Джонса</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/week_4_close_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных\n",
    "В этом задании мы будем работать с данными о стоимостях акций 30 крупнейших компаний США. На основе этих данных можно оценить состояние экономики, например, с помощью индекса Доу-Джонса. Со временем состав компаний, по которым строится индекс, меняется. Для набора данных был взят период с 23.09.2013 по 18.03.2015, в котором набор компаний был фиксирован (подробнее почитать о составе можно по ссылке из материалов).\n",
    "\n",
    "Одним из существенных недостатков индекса Доу-Джонса является способ его вычисления — при подсчёте индекса цены входящих в него акций складываются, а потом делятся на поправочный коэффициент. В результате, даже если одна компания заметно меньше по капитализации, чем другая, но стоимость одной её акции выше, то она сильнее влияет на индекс. Даже большое процентное изменение цены относительно дешёвой акции может быть нивелировано незначительным в процентном отношении изменением цены более дорогой акции.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инструкции по выполнению\n",
    "Метод главных компонент реализован в пакете `scikit-learn` в модуле `decomposition` в классе `PCA`. Основным параметром является количество компонент **(n_components)**. Для обученного преобразования этот класс позволяет вычислять различные характеристики. Например, поле **explained_variance_ratio_** содержит процент дисперсии, который объясняет каждая компонента. Поле **components_** содержит информацию о том, какой вклад вносят признаки в компоненты. Чтобы применить обученное преобразование к данным, можно воспользоваться методом **transform**.\n",
    "\n",
    "Для нахождения коэффициента корреляции Пирсона можно воспользоваться функцией **corrcoef** из пакета numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. На загруженных данных обучите преобразование PCA с числом компоненты равным 10. Скольких компонент хватит, чтобы объяснить 90% дисперсии?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['date'].apply(lambda d: pd.to_datetime(d))\n",
    "\n",
    "X = data.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PCA(n_components=10)\n",
    "\n",
    "model.fit(X)\n",
    "\n",
    "model.explained_variance_ratio_.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Примените построенное преобразование к исходным данным и возьмите значения первой компоненты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Загрузите информацию об индексе Доу-Джонса из файла djia_index.csv. Чему равна корреляция Пирсона между первой компонентой и индексом Доу-Джонса?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9096522193050236"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djia = pd.read_csv('data/week_4_djia_index.csv')\n",
    "\n",
    "np.corrcoef(test[:,0], djia['^DJI'])[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Какая компания имеет наибольший вес в первой компоненте? Укажите ее название с большой буквы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V       0.579684\n",
       "MMM     0.329616\n",
       "UNH     0.321564\n",
       "HD      0.288996\n",
       "GS      0.251227\n",
       "DIS     0.233906\n",
       "NKE     0.211889\n",
       "TRV     0.189480\n",
       "BA      0.120645\n",
       "DD      0.114090\n",
       "INTC    0.093132\n",
       "JNJ     0.091395\n",
       "WMT     0.087161\n",
       "PG      0.077732\n",
       "MSFT    0.076230\n",
       "MRK     0.071390\n",
       "UTX     0.053683\n",
       "CSCO    0.050484\n",
       "JPM     0.046988\n",
       "KO      0.029055\n",
       "PFE     0.023092\n",
       "AXP     0.016138\n",
       "VZ      0.000109\n",
       "GE     -0.006205\n",
       "T      -0.007206\n",
       "MCD    -0.026107\n",
       "XOM    -0.042942\n",
       "CAT    -0.051661\n",
       "CVX    -0.125860\n",
       "IBM    -0.264999\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X.columns,model.components_[0]))).sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
